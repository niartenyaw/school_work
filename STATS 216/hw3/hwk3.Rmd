# STATS 216, Homework #3
========================================================
### Aaron Wayne
### Collaborators: Andrew Adams, Roberto Goizueta, Sam Finlayson
--------------------------------------------------------

## Problem 1

a) With k predictors, best subset will have the smallest training RSS because it doesn't have to be a subset of previous sets like forward and backward. By definition it is the best fit to the training data. The other methods can have the same training error as best subet but never a lower training error.

b) With k predictors, it depends on the data. Best subset can potentially overfit if there is high variance and it isn't certain that the best model of the three will be from 

c)

i) True. Forward stepwise does not allow you to drop predictors from one set to the next.

ii) True. For backwards stepwise step k you take the k+1 set and remove one of the predictors.

iii) False. Backwards and forwards don't have to give the same subsets.

iv) False. Again, backwards and forwards don't have to give the same subsets. Having multiple predictors changes how important each predictor is compared to looking at each one individually.

v) True. Since every possible subset is considered in best subset, one of the subsets in k must be a subset of a k+1 subset.


## Problem 2

a) This is simply equal to 0. The only possible function in which itself is 0 to not have an infinite penalty is 0.

b) This is a straight horizontal line because its first derivative must be 0 to not have an infinite penalty. This will be at the average y value.

c) This is a straight line because there is an infinite penalty for a second derivative so it must equal 0. This is the linear least squares line.

d) This is a quadratic because its third derivative is 0.

e) This is the very wiggly function that completely interpolates the data.

## Problem 3

### a
```{r}
load("../body.RData")
plot(Y$Weight, Y$Height, col=Y$Gender+1, main="Boxers by Gender")
legend("bottomright", legend=c("0","1"), fill=c(1,2))
```

It appears that "1" corresponds to "Male".

### b

```{r}
library(pls)

test = sort(sample(1:nrow(X), 200))
train = (1:nrow(X))[-test]

pcr.form <- pcr( Y$Weight ~ . , data=X, subset=train, scale=T, validation='CV')
plsr.form <- plsr( Y$Weight ~ . , data=X, subset=train, scale=T, validation='CV')
```

Although all of the data points are measured in the units (cm), these units have a very different meaning for each of the body parts being measured.  We are interested in the relative variation in each body part, which may be different for each variable.


### c

```{r}
summary(pcr.form)
summary(plsr.form)
```

As seen above, PCR tends to explain a higher percentage of the variance accross X, whereas PLSR tends to explain a higher percentage of variance accross Y.  This isn't surprising, since PCR is unsupervised and PLSR is supervised.  PCR reduces the dimensionality of the variables by explaining as high a percentage of their variance as possible -- this is done on the assumption that the variance of the predictors will correlate with the variance of the response.  PLSR does not rely on this assumption as heavily, and as such reduces the dimensionality AFTER determining the set of features that are predictive of Y.

#### d

```{r}
par(mfrow=c(1,2))
validationplot(pcr.form, main="PCR", val.type="MSEP", xlim=c(0,10))
validationplot(plsr.form, main="PLSR", val.type="MSEP",xlim=c(0,10))
```

The minimum values of the MSEP appear to occur close to 3 components for PCR and 2 components for PLSR, so those are likely the number of components we would pick.  However, if we were to be conservative, we might pick a single component from each, since the *vast* majority of the predictive value of the models comes from the first component in each case.

#### e

We begin by examining the loading values for each of the components we which to use:

```{r}
pcr.form$loadings[,1:3]
plsr.form$loadings[,1:2]
```

With both models, almost every variable receives a substantial weight.  As such, we can not immediately remove any of the variables.  We will try some subset selection methods instead.

First, best subsets:

```{r}
library(leaps)
regfit.full = regsubsets(Y$Weight ~ . , data=X, subset=train)
summary(regfit.full)
```

Waist girth, hip girth, forearm girth, shoulder girth, and knee girth seem to be the initially salient variables.

Finally, the LASSO:

```{r}
dev.off()
library(glmnet)
grid=10^seq( 10, -2, length=100)
lasso.mod <- glmnet( as.matrix(X[train,]), Y$Weight[train], alpha=1, lambda=grid)

plot(lasso.mod, label=T)
legend("bottomleft", names(X), fill=(1:length(names(X))), cex=.5, ncol=3)

```

This seems to select similar, but slightly different variables.

#### f

``` {r}
pcr.pred <- predict(pcr.form, X[test,],ncomp=2)
mean((pcr.pred-Y$Weight[test])^2)

plrs.pred <- predict(plsr.form, X[test,],ncomp=3)
mean((plrs.pred-Y$Weight[test])^2)

cv.out <- cv.glmnet(as.matrix(X[train,]), Y$Weight[train], alpha=1)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s=bestlam, newx=as.matrix(X[test,]))
mean((lasso.pred - Y$Weight[test])^2)
```

LASSO by a nose!


## Problem 4

#### a
```{r}
h <- function(x, y){
  if(x > y){
    return((x - y)^3)
  }
  else{
    return(0)
  }
}
```

#### b

```{r}
hs <- function(xs, z){
  sapply(xs, h, z)
}
```

#### c

```{r}
splinebasis <- function(xs, zs){
  cbind(xs, xs^2, xs^3,
        sapply(zs, function(z) hs(xs, z))
               )
}

```

#### d

```{r}
set.seed(1337)
x = runif(100)
y = sin(10*x)
```

#### e

```{r}

knots <- function(k){
    1:k / (k+1)
  }

plotSpline <- function(k){
  lm.fit <- lm(y ~ splinebasis(x, knots(k)))
  
  curve(sin(10*x), main=paste(c("Spline with", k, "Knots",collapse=" ")))
  points(x,y)
  points(x, predict(lm.fit), col=2)
}

plotSpline(3)

```

#### f

```{r}
par(mfrow=c(3,3))
sapply(1:9, plotSpline)
dev.off()
```

#### g

```{r}
library(boot)
cvKnots <- function(numKnots) {
  cv.error.10 <- rep(0,numKnots)
  dat = data.frame(cbind(y,x))
  for (k in 1:numKnots){
    glm.fit <- glm(y ~ splinebasis(x, knots(k)), data=dat)
    cv.error.10[k] <- cv.glm(dat, glm.fit, K=10)$delta[1]
  }
  
  plot(cv.error.10, type='b', main="10-Fold CV Error \n By Number of Knots", xlab="knots", ylab="Prediction MSE")
  which.min(cv.error.10)
}

cvKnots(10)
#cvKnots(25)

```



